{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用于特征提取和图像匹配变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特征提取\n",
    "def extract_features(image):\n",
    "    feature_extractor = cv2.SIFT_create(nfeatures=10000,nOctaveLayers=4,contrastThreshold=0.02,edgeThreshold=10,sigma=1.0)\n",
    "    keypoints, descriptors = feature_extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# def extract_features_orb(image):\n",
    "#     orb = cv2.ORB_create(nfeatures=3000)\n",
    "#     keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "#     if descriptors is not None:\n",
    "#         descriptors = descriptors.astype(np.float32)\n",
    "#     else:\n",
    "#         descriptors = np.array([])  # 或者设置一个默认的空描述符\n",
    "#     return keypoints, descriptors\n",
    "\n",
    "# 2. 特征匹配\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.5 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "# 3. 变换估计\n",
    "def estimate_transform(keypoints1, keypoints2, good_matches):\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    # 使用RANSAC算法估计变换矩阵\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return M\n",
    "\n",
    "#4. 变换应用\n",
    "def apply_transform(image, M):\n",
    "    # 应用估计的变换矩阵到图像\n",
    "    transformed_image = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]))\n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一次配准\n",
    "image1 = cv2.imread('origin_images/2.png', cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread('origin_images/222.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 1. 特征提取\n",
    "keypoints1, descriptors1 = extract_features(image1)\n",
    "keypoints2, descriptors2 = extract_features(image2)\n",
    "\n",
    "# 2. 特征匹配\n",
    "good_matches = match_features(descriptors1, descriptors2)\n",
    "\n",
    "# 3. 变换估计\n",
    "M = estimate_transform(keypoints1, keypoints2, good_matches)\n",
    "\n",
    "# 4. 变换应用\n",
    "transformed_image = apply_transform(image1, M)\n",
    "cv2.imwrite('transformed2to222-0.5.png', transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pyramid_match_features(image1, image2, levels=3):\n",
    "#     # 创建图像金字塔\n",
    "#     pyramid1 = [image1]\n",
    "#     pyramid2 = [image2]\n",
    "#     for _ in range(levels - 1):\n",
    "#         image1 = cv2.pyrDown(image1)\n",
    "#         image2 = cv2.pyrDown(image2)\n",
    "#         pyramid1.append(image1)\n",
    "#         pyramid2.append(image2)\n",
    "#     # 存储金字塔中每一级的变换矩阵\n",
    "#     transforms = []\n",
    "#     for level in range(levels):\n",
    "#         # 提取特征\n",
    "#         keypoints1, descriptors1 = extract_features(pyramid1[level])\n",
    "#         keypoints2, descriptors2 = extract_features(pyramid2[level])\n",
    "#         # 特征匹配\n",
    "#         good_matches = match_features(descriptors1, descriptors2)\n",
    "#         # 变换估计\n",
    "#         M = estimate_transform(keypoints1, keypoints2, good_matches)\n",
    "#         # 保存变换矩阵\n",
    "#         transforms.append(M)\n",
    "#         # 向上传递变换\n",
    "#         if level > 0:\n",
    "#             M = np.vstack((M, [0, 0, 1]))  # 添加齐次坐标\n",
    "#             M_inv = np.linalg.inv(M)\n",
    "#             pyramid2[level - 1] = apply_transform(pyramid2[level - 1], M_inv)\n",
    "#     # 最终变换矩阵\n",
    "#     final_M = transforms[-1]\n",
    "#     return final_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_pyra = pyramid_match_features(image1,image2)\n",
    "# M_pyra = M_pyra.astype(np.float32)  # 将变换矩阵转换为浮点数类型\n",
    "# # if M_pyra.shape != (3, 3):\n",
    "#     # raise ValueError(\"变换矩阵的维度不正确\")\n",
    "# # 添加齐次坐标\n",
    "# M_pyra = np.vstack((M_pyra, [0, 0, 1]))\n",
    "\n",
    "# # 应用变换\n",
    "# transformed_image = cv2.warpPerspective(image1, M_pyra, (image1.shape[1], image1.shape[0]))\n",
    "# cv2.imwrite('transformed2to222_pyra.png', transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 二次配准\n",
    "# image11 = transformed_image\n",
    "# # 1. 特征提取\n",
    "# keypoints11, descriptors11 = extract_features(image11)\n",
    "# # 2. 特征匹配\n",
    "# good_matches2 =match_features(descriptors11, descriptors2)\n",
    "# # 3. 变换估计\n",
    "# M = estimate_transform(keypoints11, keypoints2, good_matches2)\n",
    "# # 4. 变换应用\n",
    "# transformed_image = apply_transform(image11, M)\n",
    "# cv2.imwrite('2transformed2to222.png', transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后面是SIFT和BFMatch合理性判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一次配准\n",
    "# 1. 特征提取\n",
    "keypoints1, descriptors1 = extract_features(image1)\n",
    "keypoints2, descriptors2 = extract_features(image2)\n",
    "\n",
    "img3 = cv2.drawKeypoints(image1,keypoints1,image1,color=(255,0,255))\n",
    "img4 = cv2.drawKeypoints(image2,keypoints2,image2,color=(255,0,255))\n",
    "hmerge = np.hstack((img3, img4))\n",
    "# pillow_image = Image.fromarray(cv2.cvtColor(hmerge, cv2.COLOR_BGR2RGB))\n",
    "# pillow_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcher解决匹配\n",
    "#可能还得试试其他的匹配方法和\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(descriptors1,descriptors2, k=2)\n",
    "#print(matches)\n",
    "#print(len(matches))\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.5*n.distance:\n",
    "        good.append([m])\n",
    "img5 = cv2.drawMatchesKnn(image1,keypoints1,image2,keypoints2,matches,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS | cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "pillow_image = Image.fromarray(cv2.cvtColor(img5, cv2.COLOR_BGR2RGB))\n",
    "pillow_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img6 = cv2.drawMatchesKnn(image1,keypoints1,image2,keypoints2,good,None,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS | cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "pillow_image = Image.fromarray(cv2.cvtColor(img6, cv2.COLOR_BGR2RGB))\n",
    "pillow_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
